[supervisord]
nodaemon=true

[program:diffbot-llm-inference]
command=/bin/bash -c "sh ./start_server.sh 2>&1 | tee -a /var/log/diffbot.log | cat";
autostart=true
autorestart=true
stdout_logfile=/dev/stdout
stderr_logfile=/dev/stderr
stdout_logfile_maxbytes=0
stderr_logfile_maxbytes=0

[program:vllm]
command=/bin/bash -c "python3 -m vllm.entrypoints.openai.api_server --model diffbot/Llama-3.1-Diffbot-Small-2412 --served-model-name diffbot-small --enable-prefix-caching --quantization fp8 --tensor-parallel-size 2 2>&1 | tee -a /var/log/vllm.log | cat"
; command=/bin/bash -c "python3 -m vllm.entrypoints.openai.api_server --model diffbot/Llama-3.3-Diffbot-Small-XL-2412 --served-model-name diffbot-small-xl --enable-prefix-caching --quantization fp8 --tensor-parallel-size 2 2>&1 | tee -a /var/log/vllm.log | cat"
autostart=true
autorestart=true
stdout_logfile=/dev/stdout
stderr_logfile=/dev/stderr
stdout_logfile_maxbytes=0
stderr_logfile_maxbytes=0
